{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppsplitting av kunnskapsartikler til dataprodukt\n",
    "\n",
    "Notebook for å kjøre samme oppsplitting av artiklene i NKS Kunnskapsbasen som `nks_vdb`, og dytte resultatet til en tabell i BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import Iterable\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from langchain_core.documents import Document\n",
    "from nks_vdb.knowledgebase import clean_documents, get_column_metadata, split_documents\n",
    "from nks_vdb.settings import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ønsker litt andre metadata- og content-kolonner her enn det som brukes i `nks_vdb`-lasten. \n",
    "Vi definerer derfor koden for dokumentinnlastingen på nytt her framfor å hente fra `nks_vdb.knowledgebase`.\n",
    "\n",
    "(Vi henter bl.a. artikkeltekstene som finnes på nynorsk og engelsk, ikke bare bokmål)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_COLUMNS: list[str] = [\n",
    "    \"ArticleType\",\n",
    "    \"DataCategories\",\n",
    "    \"KnowledgeArticleId\",\n",
    "    \"KnowledgeArticle_QuartoUrl\",\n",
    "    \"LastModifiedDate\",\n",
    "    \"Title\",\n",
    "    \"VersionNumber\",\n",
    "]\n",
    "CONTENT_COLUMNS: list[str] = [\n",
    "    \"Article__c\",\n",
    "    \"NKS_User__c\",\n",
    "    \"WhoDoesWhat__c\",\n",
    "    \"EmployerInformation__c\",\n",
    "    \"EmployerInformationInternal__c\",\n",
    "    \"InternationalInformation__c\",\n",
    "    \"InternationalInformationInternal__c\",\n",
    "    \"AdvisorInformation__c\",\n",
    "    \"AdvisorInformationInternal__c\",\n",
    "    \"How_you_send_a_task__c\",\n",
    "    \"NKS_English__c\",\n",
    "    \"NKS_English_Employer__c\",\n",
    "    \"NKS_Nynorsk__c\",\n",
    "    \"NKS_Nynorsk_Employer__c\",\n",
    "]\n",
    "\n",
    "\n",
    "def __format_query(\n",
    "    content_column: str, min_length: int = 30, last_modified: datetime | None = None\n",
    ") -> str:\n",
    "    \"\"\"Metode for å formatere spørring til kunnskapsbasen for å hente dokumenter.\n",
    "\n",
    "    Args:\n",
    "        content_column:\n",
    "            Kolonnen som skal benyttes som innhold for dokumentet\n",
    "        min_length:\n",
    "            Det må minst være `min_length` antall tegn i innholdet for at det\n",
    "            skal regnes som et dokument. Dette brukes for å filtrere ut kolonner\n",
    "            som ikke er NULL eller bare inneholder ' ', men som fortsatt ikke\n",
    "            inneholder meningsfylt tekst.\n",
    "        last_modified:\n",
    "            Valgbar tidspunkt for å filtrere kolonner som er eldre enn\n",
    "            `last_modified`\n",
    "    Returns:\n",
    "        SQL spørring for å hente ut `content_column` som et dokument\n",
    "    \"\"\"\n",
    "    metadata_columns = \", \".join(METADATA_COLUMNS)\n",
    "    sql = (\n",
    "        \"SELECT {metadata_columns},\"\n",
    "        \" {content_column} AS Content,\"\n",
    "        \" FROM `kunnskapsbase.kunnskapsartikler`\"\n",
    "        \" WHERE PublishStatus = 'Online'\"\n",
    "        \" AND {content_column} IS NOT NULL\"\n",
    "        \" AND {content_column} != ''\"\n",
    "        \" AND CHAR_LENGTH({content_column}) >= {min_length}\"\n",
    "    )\n",
    "    if last_modified:\n",
    "        sql += f\" AND LastModifiedBQ > '{last_modified.isoformat()}'\"\n",
    "    return sql.format(\n",
    "        metadata_columns=metadata_columns,\n",
    "        content_column=content_column,\n",
    "        min_length=min_length,\n",
    "    )\n",
    "\n",
    "\n",
    "def load(last_modified: datetime | None = None) -> Iterable[Document]:\n",
    "    \"\"\"Last inn kunnskapsbasen fra BigQuery og produser LangChain dokumenter.\n",
    "\n",
    "    Args:\n",
    "        last_modified (valgbar):\n",
    "            Bare last inn dokumenter nyere enn `last_modified`\n",
    "    Returns:\n",
    "        Generator som produserer dokumenter\n",
    "    \"\"\"\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    client = bigquery.Client(project=settings.gcp.prosjekt)\n",
    "    # Vi itererer gjennom alle innholdkolonnene for å minimere minnebruk ved å\n",
    "    # ikke hente ut alle kunnskapsartikler på en gang\n",
    "    for column in CONTENT_COLUMNS:\n",
    "        query = __format_query(column, last_modified=last_modified)\n",
    "        raw_results = client.query(query).result()\n",
    "        # For hver rad (mao. hver artikkel) henter vi ut innhold og metadata som\n",
    "        # tilsammen produserer et dokument\n",
    "        for row in raw_results:\n",
    "            metadata = {k: v for k, v in row.items() if k in METADATA_COLUMNS}\n",
    "            metadata |= get_column_metadata(column, row[\"ArticleType\"], row[\"Title\"])\n",
    "            content = row[\"Content\"]\n",
    "            yield Document(page_content=content, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hent artikkelseksjoner og splitt dem opp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = split_documents(clean_documents(docs), chunk_size=1500, overlap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dytte data til BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nks_vdb`-koden jobber med dokumentene som Lanchain-dokumenter. For å lettere gjøre skrive dataene til BigQuery kan vi konvertere til en pandas dataframe først."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endrer fra langchain Documents til en pandas DataFrame\n",
    "data = []\n",
    "for doc in splits:\n",
    "    doc_data = {\"page_content\": doc.page_content}\n",
    "    doc_data.update(doc.metadata)\n",
    "    data.append(doc_data)\n",
    "df_transformed = pd.DataFrame(data)\n",
    "\n",
    "# Renamer en del kolonner\n",
    "df_transformed = df_transformed.rename(\n",
    "    columns={\n",
    "        \"page_content\": \"content\",\n",
    "        \"ArticleType\": \"type\",\n",
    "        \"VersionNumber\": \"version_number\",\n",
    "        \"DataCategories\": \"data_categories\",\n",
    "        \"KnowledgeArticleId\": \"knowledge_article_id\",\n",
    "        \"KnowledgeArticle_QuartoUrl\": \"url\",\n",
    "        \"LastModifiedDate\": \"last_modified\",\n",
    "        \"Title\": \"title\",\n",
    "        \"Section\": \"section\",\n",
    "        \"Tab\": \"tab\",\n",
    "        \"Fragment\": \"anchor\",\n",
    "        \"Headers\": \"headers\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Stokker om på rekkefølgen\n",
    "df_transformed = df_transformed[\n",
    "    [\n",
    "        \"knowledge_article_id\",\n",
    "        \"version_number\",\n",
    "        \"type\",\n",
    "        \"data_categories\",\n",
    "        \"last_modified\",\n",
    "        \"title\",\n",
    "        \"section\",\n",
    "        \"tab\",\n",
    "        \"headers\",\n",
    "        \"content\",\n",
    "        \"url\",\n",
    "        \"anchor\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Gjør om `data_categories` og `headers` til en liste av strings slik at de kan være REPEATED fields i BigQuery\n",
    "df_transformed[\"data_categories\"] = df_transformed[\"data_categories\"].apply(\n",
    "    lambda x: x.split(\",\")\n",
    ")\n",
    "df_transformed[\"headers\"] = df_transformed[\"headers\"].apply(\n",
    "    lambda x: [f\"{k} {v}\" for k, v in x.items()]\n",
    ")\n",
    "\n",
    "# Legg på info om hvilken dag lasten skjedde (dagens dato)\n",
    "df_transformed[\"load_to_bq_date\"] = pd.to_datetime(\"today\").normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigQuery config\n",
    "prosjekt = settings.gcp.prosjekt\n",
    "datasett = \"kunnskapsbase\"\n",
    "tabellnavn = \"kunnskapsartikler_oppsplittet\"\n",
    "table_id = f\"{prosjekt}.{datasett}.{tabellnavn}\"\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\n",
    "        \"knowledge_article_id\", \"STRING\", description=\"Id for artikkelen i Salesforce\"\n",
    "    ),\n",
    "    bigquery.SchemaField(\"version_number\", \"STRING\", description=\"Versjonsnummer\"),\n",
    "    bigquery.SchemaField(\"type\", \"STRING\", description=\"Artikkeltype\"),\n",
    "    bigquery.SchemaField(\n",
    "        \"data_categories\",\n",
    "        \"STRING\",\n",
    "        mode=\"REPEATED\",\n",
    "        description=\"Tema-tagger tilknyttet artikkelen\",\n",
    "    ),\n",
    "    bigquery.SchemaField(\n",
    "        \"last_modified\", \"DATETIME\", description=\"Når ble artikkelen sist endret\"\n",
    "    ),\n",
    "    bigquery.SchemaField(\"title\", \"STRING\", description=\"Tittel på artikkelen\"),\n",
    "    bigquery.SchemaField(\n",
    "        \"section\",\n",
    "        \"STRING\",\n",
    "        description=\"Refererer til hvilken artikkel-seksjon i Salesforce innholdet er tilknyttet\",\n",
    "    ),\n",
    "    bigquery.SchemaField(\n",
    "        \"tab\",\n",
    "        \"STRING\",\n",
    "        description=\"Refererer til hvilken artikkel-tab i Salesforce innholdet er tilknyttet\",\n",
    "    ),\n",
    "    bigquery.SchemaField(\n",
    "        \"headers\",\n",
    "        \"STRING\",\n",
    "        mode=\"REPEATED\",\n",
    "        description=\"Underoverskrifter tilknyttet innholdet\",\n",
    "    ),\n",
    "    bigquery.SchemaField(\"content\", \"STRING\", description=\"Selve innholdet\"),\n",
    "    bigquery.SchemaField(\n",
    "        \"url\", \"STRING\", description=\"Lenke til artikkelvisningen på datamarkedsplassen\"\n",
    "    ),\n",
    "    bigquery.SchemaField(\n",
    "        \"anchor\",\n",
    "        \"STRING\",\n",
    "        description=\"Anker for innhold i visningen på datamarkedsplassen\",\n",
    "    ),\n",
    "    bigquery.SchemaField(\n",
    "        \"load_to_bq_date\",\n",
    "        \"DATE\",\n",
    "        description=\"Når dataene ble kopiert til denne tabellen\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "client = bigquery.Client(f\"{prosjekt}\")\n",
    "\n",
    "\n",
    "def dytt_data_til_bigquery(df, table_id):\n",
    "    \"\"\"Hjelpemetode for å skrive pandas dataframe til BigQuery.\"\"\"\n",
    "    job = client.load_table_from_dataframe(\n",
    "        df, table_id, job_config=job_config\n",
    "    )  # Make an API request.\n",
    "    job.result()  # Wait for the job to complete.\n",
    "    print(f\"  {len(df)} rader skrevet til tabell\")\n",
    "\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=schema,\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skriv dataene til BigQuery\n",
    "dytt_data_til_bigquery(df_transformed, table_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
