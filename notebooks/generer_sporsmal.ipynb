{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generer spørsmål om NKS Kunnskapsbasen\n",
    "\n",
    "Denne notatboken inneholder en oppskrift på hvordan å generere _syntetiske_\n",
    "spørsmål om NKS sin Kunnskapsbase.\n",
    "\n",
    "Den beste måten å lage et datasettet på er ved å få ekspertbrukere til å\n",
    "generere spørsmål og svar til den originale kunnskapsbasen og bruke dette\n",
    "datasettet som en fasit å måle vektordatabasen opp i mot. Denne fremgangsmåten\n",
    "er dessverre veldig tidkrevende og det kan ta veldig lang tid fra systemet er\n",
    "satt opp til man får muligheten til å lage datasettet for å teste.\n",
    "\n",
    "En annen måte å generere et tilsvarende syntetisk datasett, og det resten av\n",
    "denne notatboken tar for seg, er å be en stor språkmodell om å generere\n",
    "spørsmål på bakgrunn av den originale kunnskapsbasen. Denne fremgangsmåten er\n",
    "relativt hurtig, den kan settes opp uten at man må koordinere med ekspertbrukere\n",
    "og - utenom kostnaden ved å benytte språkmodellen, er noe alle Data Scientister i\n",
    "NAV kan gjøre. Bakdelen med fremgangsmåten er at det kan være vanskelig å svare\n",
    "på kvaliteten til spørsmålene. Tanken er med andre ord at et syntetisk datasett\n",
    "som man kan måle vektordatabaser opp mot er bedre enn ingen datasett.\n",
    "\n",
    "For å prøve å håndtere utfordringen med å vurdere kvaliteten på spørsmålene vil\n",
    "vi i denne notatboken prøve å bruke `LangGraph`. Med `LangGraph` kan man sette\n",
    "opp kjøretidsgrafer av språkmodeller som kan benyttes for å utføre forskjellige\n",
    "oppgaver. For å generere syntetiske spørsmål så kan man jo tenke seg at vi først\n",
    "vurderer om et avsnitt egner seg for å generere spørsmål. Når det er gjort så\n",
    "kan man vurdere om spørsmålet i seg selv er godt eller om spørsmålet utelukkende\n",
    "kan svares på ved hjelp av teksten som spørsmålet ble generert fra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NKS kunnskapsbase\n",
    "\n",
    "Vi kommer i denne notebook-en til å benytte NKS sin kunnskapsbase som et\n",
    "grunnlag. Det er gjort en veldig stor jobb allerede med å lese inn tekst fra\n",
    "Salesforce og putte dette på BigQuery, som vi kommer til å benytte.\n",
    "\n",
    "Måten teksten er organisert på er at hver rad i BigQuery inneholder en\n",
    "kunnskapsartikkel som har flere faste seksjoner (kolonner i BigQuery). For å\n",
    "enkelt kunne holde styr på hvilken seksjon som svarer til hva kommer vi til å be\n",
    "språkmodellen om å lage spørsmål på bakgrunn av hver seksjon. Dette gir god\n",
    "granularitet på spørsmålene og det blir enklere å sjekke at vektordatabasen(e)\n",
    "klarer å hente ut riktig artikkel i ettertid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "\n",
    "# Opprett rich objekt for pen utskrift\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Håndtering av miljøvariabler\n",
    "\n",
    "For å kunne koble til Azure OpenAI Services trenger vi et par miljøvariabler. Vi\n",
    "benytter [`dotenv`](https://pypi.org/project/python-dotenv/) for dette slik at\n",
    "det er konfigurerbart og repeterbart.\n",
    "\n",
    "Pass på at du har en `.env` fil som inneholder:\n",
    "\n",
    "- `AZURE_OPENAI_ENDPOINT`\n",
    "- `AZURE_OPENAI_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "assert (\n",
    "    \"AZURE_OPENAI_ENDPOINT\" in os.environ\n",
    "), \"Mangler Azure endpoint som miljøvariabel!\"\n",
    "assert (\n",
    "    \"AZURE_OPENAI_API_KEY\" in os.environ\n",
    "), \"Mangler Azure API nøkkel som miljøvariabel!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forberede database for generert datasett\n",
    "\n",
    "For å enkelt kunne gjenbruke og slå sammen informasjon fra den originale\n",
    "kunnskapsbasen og det genererte datasettet, setter vi opp en egen tabell på\n",
    "BigQuery som kan inneholde spørsmål og tilhørende artikkel ID samt seksjonen\n",
    "(kolonnen i den originale kunnskapsbasen) som kan svare på spørsmålet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project=\"nks-aiautomatisering-prod-194a\")\n",
    "table_id = \"nks-aiautomatisering-prod-194a.kunnskapsbase.syntetiske_sporsmal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.bigquery import SchemaField\n",
    "\n",
    "# Database skjema på BigQuery for spørsmålsdatasettet\n",
    "schema = [\n",
    "    SchemaField(\"id\", \"STRING\", mode=\"REQUIRED\", description=\"ID til spørsmålet\"),\n",
    "    SchemaField(\n",
    "        \"knowledge_article_id\",\n",
    "        \"STRING\",\n",
    "        mode=\"REQUIRED\",\n",
    "        description=\"ID til tilhørende kunnskapsartikkel\",\n",
    "    ),\n",
    "    SchemaField(\n",
    "        \"knowledge_column\",\n",
    "        \"STRING\",\n",
    "        mode=\"REQUIRED\",\n",
    "        description=\"Kolonne spørsmålet hører til\",\n",
    "    ),\n",
    "    SchemaField(\n",
    "        \"created\",\n",
    "        \"DATETIME\",\n",
    "        mode=\"REQUIRED\",\n",
    "        description=\"Tidspunkt spørsmålet ble lastet opp\",\n",
    "    ),\n",
    "    SchemaField(\n",
    "        \"prompt\",\n",
    "        \"STRING\",\n",
    "        mode=\"REQUIRED\",\n",
    "        description=\"Prompt som ble brukt for å generere spørsmål (uten selve teksten)\",\n",
    "    ),\n",
    "    SchemaField(\n",
    "        \"question\",\n",
    "        \"STRING\",\n",
    "        mode=\"REQUIRED\",\n",
    "        description=\"Spørsmål til kunnskapsartikkelen\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opprett database hvis den ikke allerede finnes\n",
    "table_ref = bigquery.TableReference.from_string(table_id=table_id)\n",
    "table = client.create_table(table_ref, exists_ok=True)\n",
    "if not table.schema:\n",
    "    table.schema = schema\n",
    "    client.update_table(table, fields=[\"schema\"])\n",
    "    console.print(f\"[bold magenta]Opprettet/Endret database[/] '{table.full_table_id}'\")\n",
    "else:\n",
    "    console.print(\"Spørsmålsdatabase [bold green]eksisterer allerede\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppsett av kjøretidsgraf\n",
    "\n",
    "Før vi kan prosessere kunnskapsartikler må vi først definere hvordan disse\n",
    "artiklene skal prosesseres.\n",
    "\n",
    "For å prosessere kunnskapsartiklene kommer vi til å opprette en kjøretidsgraf\n",
    "som avgjør om innholdet i kunnskapsartikkelen egner seg for å generere et\n",
    "spørsmål fra, deretter generere et spørsmål, før vi tilslutt prøver å vurdere om\n",
    "spørsmålet sammen med teksten gir mening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Egner kunnskapsartikkel seg for spørsmålsgenerering?\n",
    "\n",
    "Vi starter med å opprette en flyt for å vurdere om en kunnskapsartikkel egner\n",
    "seg for å generere spørsmål."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "BinaryScore = Literal[\"yes\", \"no\"]\n",
    "\"\"\"Svar fra språkmodell som enten er Ja eller Nei\"\"\"\n",
    "\n",
    "\n",
    "# Svaret vi forventer fra språkmodellen når den evaluerer en kunnskapsartikkel\n",
    "class EvaluateContent(BaseModel):\n",
    "    \"\"\"Evaluer innholdet i en kunnskapsartikkel for egnethet for spørsmålsgenerering.\"\"\"\n",
    "\n",
    "    score: BinaryScore = Field(\n",
    "        description=\"Content is well suited for question generation, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Modellen som skal evaluere kunnskapsartikler\n",
    "llm_evaluator = AzureChatOpenAI(\n",
    "    api_version=\"2023-03-15-preview\", azure_deployment=\"gpt-4o-mini\", temperature=0.0\n",
    ").with_structured_output(EvaluateContent)\n",
    "\n",
    "# Ledetekst for å evaluere en kunnskapsartikkel\n",
    "prompt = \"\"\"You are a grader assessing the relevance of a retrieved document for \\\n",
    "synthetic question generation. If the document contains enough text and meaningful \\\n",
    "questions could be generated based on the text, grade it as relevant. It does not need \\\n",
    "to be a stringent test. The goal is to try and filter out documents that are difficult \\\n",
    "to generate meaningful questions from. Give a binary score 'yes' or 'no' to indicate \\\n",
    "whether the document is relevant or not.\"\"\"\n",
    "\n",
    "eval_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", prompt), (\"human\", \"Retrieved document:\\n\\n{document}\")]\n",
    ")\n",
    "# LangChain runnable for å vurdere en kunnskapsartikkel\n",
    "eval_grader = eval_prompt | llm_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitable = eval_grader.invoke(\n",
    "    {\n",
    "        \"document\": \"NAVs samfunnsoppdrag er å bidra til sosial og økonomisk tryggleik og fremme overgang til arbeid og aktivitet. målet er å skape eit inkluderande samfunn, eit inkluderande arbeidsliv og ein velfungerande arbeidsmarknad.\"\n",
    "    }\n",
    ")\n",
    "console.print(f\"Er teksten godt nok for et spørsmål: {suitable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generere spørsmål\n",
    "\n",
    "Det neste vi oppretter er en flyt for å generere spørsmål fra en\n",
    "kunnskapsartikkel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm_generator = AzureChatOpenAI(\n",
    "    api_version=\"2023-03-15-preview\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "prompt = \"\"\"You are a synthetic question generation system. You will be given a \\\n",
    "document and should generate a question that can be answered by the document alone. \\\n",
    "The question must be a complete sentence and must be in Norwegian. If given the \\\n",
    "question a user should be able to answer it based on the text in the given document.\"\"\"\n",
    "\n",
    "question_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", prompt), (\"human\", \"Document:\\n\\n{document}\")]\n",
    ")\n",
    "# LangChain runnable for å generere et spørsmål\n",
    "question_generator = question_gen_prompt | llm_generator | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = question_generator.invoke(\n",
    "    {\n",
    "        \"document\": \"NAVs samfunnsoppdrag er å bidra til sosial og økonomisk tryggleik og fremme overgang til arbeid og aktivitet. Målet er å skape eit inkluderande samfunn, eit inkluderande arbeidsliv og ein velfungerande arbeidsmarknad.\"\n",
    "    }\n",
    ")\n",
    "console.print(f\"Forslag til spørsmål: [bold blue]{question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluer spørsmål fra kunnskapsartikkel\n",
    "\n",
    "Før vi konkluderer med at et spørsmål er godt nok ber vi språkmodellen om å\n",
    "vurdere dette faktumet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeQuestion(BaseModel):\n",
    "    \"\"\"Evaluering av syntetisk spørsmål.\"\"\"\n",
    "\n",
    "    score: BinaryScore = Field(\n",
    "        description=\"Question makes sense given the document, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm_grader = AzureChatOpenAI(\n",
    "    api_version=\"2023-03-15-preview\", azure_deployment=\"gpt-4o-mini\", temperature=0.0\n",
    ").with_structured_output(GradeQuestion)\n",
    "prompt = \"\"\"You are a grader assessing whether a question makes sense \\\n",
    "given a document which must contain the answer to the question. Give a \\\n",
    "binary score 'yes' or 'no'. 'Yes' means that the question makes sense given \\\n",
    "the document.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", prompt), (\"human\", \"Document:\\n\\n{document}\\n\\nQuestion: {question}\")]\n",
    ")\n",
    "question_grader = grade_prompt | llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = question_grader.invoke(\n",
    "    {\n",
    "        \"document\": \"NAVs samfunnsoppdrag er å bidra til sosial og økonomisk tryggleik og fremme overgang til arbeid og aktivitet. målet er å skape eit inkluderande samfunn, eit inkluderande arbeidsliv og ein velfungerande arbeidsmarknad.\",\n",
    "        \"question\": question,\n",
    "    }\n",
    ")\n",
    "console.print(f\"Er det et godt spørsmål: {grade}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sett opp kjøretidsgrafen\n",
    "\n",
    "For å koble dette sammen til et system oppretter vi en kjøretidsgraf slik at vi\n",
    "kan inkorporere de foregående modellene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "EvalResult = Literal[\"suitable\", \"not suitable\"]\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"Tilstanden til spørsmålsgenerering kjøretidsgraf.\"\"\"\n",
    "\n",
    "    document: str\n",
    "    generated_question: str\n",
    "    good_question: bool\n",
    "\n",
    "\n",
    "# Definer flyten til kjøretidsgrafen\n",
    "def evaluate_document(state: GraphState) -> EvalResult:\n",
    "    \"\"\"Evaluer en kunnskapsartikkel om den egner seg for å generere spørsmål.\"\"\"\n",
    "    # console.print(\"---[bold magenta]Evaluer dokument[/]---\")\n",
    "    doc = state[\"document\"]\n",
    "    suitable = eval_grader.invoke({\"document\": doc})\n",
    "    if suitable.score == \"yes\":\n",
    "        return \"suitable\"\n",
    "    else:\n",
    "        return \"not suitable\"\n",
    "\n",
    "\n",
    "def generate_question(state: GraphState) -> GraphState:\n",
    "    \"\"\"Generer et spørsmål - Node i kjøretidsgrafen.\"\"\"\n",
    "    # console.print(\"---[bold magenta]Generer spørsmål[/]---\")\n",
    "    doc = state[\"document\"]\n",
    "    question = question_generator.invoke({\"document\": doc})\n",
    "    return {\"document\": doc, \"generated_question\": question}\n",
    "\n",
    "\n",
    "def grade_question(state: GraphState) -> GraphState:\n",
    "    \"\"\"Vurder om spørsmålet er godt sett i forhold til kunnskapsartikkelen.\"\"\"\n",
    "    # console.print(\"---[bold magenta]Vurder spørsmål[/]---\")\n",
    "    doc = state[\"document\"]\n",
    "    question = state[\"generated_question\"]\n",
    "    grade = question_grader.invoke({\"question\": question, \"document\": doc})\n",
    "    return {\n",
    "        \"document\": doc,\n",
    "        \"generated_question\": question,\n",
    "        \"good_question\": grade.score == \"yes\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "# Kjøretidsgrafen\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Legg til noder i grafen\n",
    "workflow.add_node(\"generate\", generate_question)\n",
    "workflow.add_node(\"grade\", grade_question)\n",
    "# Legg til kanter i grafen\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    evaluate_document,\n",
    "    {\n",
    "        \"suitable\": \"generate\",\n",
    "        \"not suitable\": END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"generate\", \"grade\")\n",
    "# Opprett flyt\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = {\n",
    "    \"document\": \"NAVs samfunnsoppdrag er å bidra til sosial og økonomisk tryggleik og fremme overgang til arbeid og aktivitet. Målet er å skape eit inkluderande samfunn, eit inkluderande arbeidsliv og ein velfungerande arbeidsmarknad.\"\n",
    "}\n",
    "res = app.invoke(inp)\n",
    "console.print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last inn kunnskapsbasen\n",
    "\n",
    "Vi benytter samme kode som `nks_vdb` for å laste inn kunnskapsbasen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nks_kbs_analyse.knowledgebase import load\n",
    "\n",
    "docs = list(load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generer spørsmål\n",
    "\n",
    "Tilslutt generer vi spørsmål fra kunnskapsbasen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from rich.progress import Progress\n",
    "\n",
    "num_to_generate = 300\n",
    "synthetic_questions: list[tuple[str, Document]] = []\n",
    "with Progress() as progress:\n",
    "    gen_task = progress.add_task(\"Lager spørsmål\")\n",
    "    while len(synthetic_questions) < num_to_generate:\n",
    "        selected = random.choices(docs, k=min(num_to_generate, 10))\n",
    "        qa_eval = app.batch([{\"document\": doc.page_content} for doc in selected])\n",
    "        good_questions = [\n",
    "            (qa[\"generated_question\"], doc)\n",
    "            for (qa, doc) in zip(qa_eval, selected)\n",
    "            if \"good_question\" in qa and qa[\"good_question\"]\n",
    "        ]\n",
    "        synthetic_questions.extend(good_questions)\n",
    "        progress.update(\n",
    "            gen_task, total=num_to_generate, completed=len(synthetic_questions)\n",
    "        )\n",
    "# Hvis vi har generert for mange spørsmål så kutter vi listen\n",
    "synthetic_questions = synthetic_questions[:num_to_generate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klargjør data for opplasting til BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import uuid\n",
    "\n",
    "today = datetime.datetime.now(datetime.UTC)\n",
    "\n",
    "rows = [\n",
    "    dict(\n",
    "        id=uuid.uuid4(),\n",
    "        knowledge_article_id=doc.metadata[\"KnowledgeArticleId\"],\n",
    "        knowledge_column=doc.metadata[\"ContentColumn\"],\n",
    "        created=today,\n",
    "        prompt=question_gen_prompt.messages[0].prompt.template,\n",
    "        question=question,\n",
    "    )\n",
    "    for question, doc in synthetic_questions\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og last opp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.prompt import Confirm\n",
    "\n",
    "if Confirm.ask(f\"Vil du laste opp {len(rows)} nye spørsmål til BigQuery?\"):\n",
    "    errors = client.insert_rows(rows=rows, table=table)\n",
    "    if errors:\n",
    "        console.print(\n",
    "            f\"[bold red]Det oppstod følgende feil ved opplasting:[/] {errors}\"\n",
    "        )\n",
    "    else:\n",
    "        console.print(\"[bold green]Opplasting ferdig!\")\n",
    "else:\n",
    "    console.print(\"[bold yellow]Hoppet over opplasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
